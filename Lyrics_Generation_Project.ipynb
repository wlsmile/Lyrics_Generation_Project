{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de569e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers\n",
    "#%pip install datasets\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import TFBartForConditionalGeneration, BartTokenizer, BartConfig, TFGPT2LMHeadModel,GPT2Tokenizer,GPT2Config, AutoTokenizer,AutoConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model, save_model, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Add,Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.random import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ca5f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15191</td>\n",
       "      <td>15191</td>\n",
       "      <td>../lyrics/michaellearnstorock/outoftheblue.html</td>\n",
       "      <td>Michael Learns To Rock Lyrics</td>\n",
       "      <td>Out Of The Blue</td>\n",
       "      <td>\\n\\r\\nI was almost about to lose my faith\\r\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17643</td>\n",
       "      <td>17643</td>\n",
       "      <td>../lyrics/beatles/illbeonmyway.html</td>\n",
       "      <td>The Beatles Lyrics</td>\n",
       "      <td>I'll Be On My Way</td>\n",
       "      <td>\\n\\r\\nThe sun is fading away\\nThat's the end o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5081</td>\n",
       "      <td>5081</td>\n",
       "      <td>../lyrics/johnnycash/idjustbefoolenoughtofall....</td>\n",
       "      <td>Johnny Cash Lyrics</td>\n",
       "      <td>I'd Just Be Fool Enough (To Fall)</td>\n",
       "      <td>\\n\\r\\nOh please don't be so careless with your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21442</td>\n",
       "      <td>21442</td>\n",
       "      <td>https://www.azlyrics.com/lyrics/nerd/1000.html</td>\n",
       "      <td>N.E.R.D &amp; Future Lyrics</td>\n",
       "      <td>1000</td>\n",
       "      <td>\\n\\n[Pharrell Williams:]\\nAh, ah\\nAssembling a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10461</td>\n",
       "      <td>10461</td>\n",
       "      <td>../lyrics/snoopdogg/wasntyourfault.html</td>\n",
       "      <td>Snoop Dogg Lyrics</td>\n",
       "      <td>Wasn't Your Fault</td>\n",
       "      <td>\\n\\n[Voice talking (echo)]\\r\\nYeah .. niggas w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0         15191       15191   \n",
       "1         17643       17643   \n",
       "2          5081        5081   \n",
       "3         21442       21442   \n",
       "4         10461       10461   \n",
       "\n",
       "                                                link  \\\n",
       "0    ../lyrics/michaellearnstorock/outoftheblue.html   \n",
       "1                ../lyrics/beatles/illbeonmyway.html   \n",
       "2  ../lyrics/johnnycash/idjustbefoolenoughtofall....   \n",
       "3     https://www.azlyrics.com/lyrics/nerd/1000.html   \n",
       "4            ../lyrics/snoopdogg/wasntyourfault.html   \n",
       "\n",
       "                          artist                          song_name  \\\n",
       "0  Michael Learns To Rock Lyrics                    Out Of The Blue   \n",
       "1             The Beatles Lyrics                  I'll Be On My Way   \n",
       "2             Johnny Cash Lyrics  I'd Just Be Fool Enough (To Fall)   \n",
       "3        N.E.R.D & Future Lyrics                               1000   \n",
       "4              Snoop Dogg Lyrics                  Wasn't Your Fault   \n",
       "\n",
       "                                              lyrics  \n",
       "0  \\n\\r\\nI was almost about to lose my faith\\r\\nW...  \n",
       "1  \\n\\r\\nThe sun is fading away\\nThat's the end o...  \n",
       "2  \\n\\r\\nOh please don't be so careless with your...  \n",
       "3  \\n\\n[Pharrell Williams:]\\nAh, ah\\nAssembling a...  \n",
       "4  \\n\\n[Voice talking (echo)]\\r\\nYeah .. niggas w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv data\n",
    "#sample_English = pd.read_csv('/content/gdrive/MyDrive/sample_English_lyrics_10000.csv')\n",
    "#sample_English.head()\n",
    "\n",
    "new_data = pd.read_csv('./lyrics_training_data.csv')\n",
    "\n",
    "# Explore the top 5 rows of the dataset\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7e2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# download and initialize the pre-trained tokenizer and model\n",
    "def load_pretrained():\n",
    "    # tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    # config = GPT2Config.from_pretrained(\"gpt2\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    #tokenizer = AutoTokenizer.from_pretrained('gpt2', is_split_into_words=True)\n",
    "    config = GPT2Config.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id, use_cache=False)\n",
    "    model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")#, config = config)\n",
    "    return tokenizer, config, model\n",
    "\n",
    "tokenizer, config, model= load_pretrained()\n",
    "#model = load_model(tokenizer.eos_token_id)\n",
    "#model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "#model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", config = config)\n",
    "#model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062b3b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n\\r\\nI was almost about to lose my faith\\r\\nWas still dreaming but feared it was too late\\n\\r\\nBut then you came along to my surprise\\r\\nAnd stole my heart before my very eyes\\n\\n[Chorus:]\\r\\nYou took me right out of the blue\\r\\nSimply by showing that you love me too\\r\\nOnly by giving me your everything\\r\\nWith a love so true you took me out of the blue\\n\\r\\nI was wondering what love was all about\\r\\nI was trying but couldn't work it out\\n\\r\\nBut then you came along to my surprise\\r\\nAnd made my frozen mind come alive\\n\\n[Chorus:]\\r\\nYou took me right out of the blue\\r\\nSimply by showing that you love me too...\\n\\r\\nYou let me out of the darkness \\r\\nYou brought me out in the sun\\r\\nI think you must be the only one for me\\r\\n'cos you took me\\n\\n[Chorus:]\\r\\nRight out of the blue\\r\\nSimply by showing that you love me too\\r\\nOnly by giving me your everything\\r\\nBreathing air below my wings\\r\\nYou took me right out of the night\\r\\nSimply by filling my heart with light\\r\\nOnly by giving me your energy\\r\\nWith a love so true you took me out of the blue\\n\",\n",
       " \"\\n\\r\\nThe sun is fading away\\nThat's the end of the day\\nAs the June light turns to moonlight\\nI'll be on my way\\n\\nJust one kiss and I'll go\\nDon't hide the tears that don't show\\nAs the June light turns to moonlight\\nI'll be on my way\\n\\nTo where the winds don't blow\\nAnd golden rivers flow\\nThis way will I go\\n\\nThey were right I was wrong\\nTrue love didn't last long\\nAs the June light turns to moonlight\\nI'll be on my way hey\\n\\nTo where the winds don't blow\\nAnd golden rivers flow\\nThis way will I go\\n\\nThey were right I was wrong\\nTrue love didn't last long\\nAs the June light turns to moonlight\\nI'll be on my way hey\\nI'll be on my way oh\\nI'll be on my way oh\\nI'll be on my way (fade out)\\n\",\n",
       " \"\\n\\r\\nOh please don't be so careless with your glances\\nDon't look at me that way and breathe a sigh\\nPlease don't get too close and let me love you\\n'Cause I just might be fool enough to try\\n\\nIt's not that I don't think I'm worthy of you\\nBut memories from the past I still recall\\nPlease don't get too close and let me love you\\n'Cause I just might be fool enough to fall\\n\\nIt's not that I don't think I'm worthy of you\\nBut memories from the past I still recall\\nOh, please don't get too close and let me love you\\n'Cause I just might be fool enough to fall\\n\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the lyrics as string into one list\n",
    "#Lyrics = [text for idx, text in enumerate(sample_English['Lyric'])]\n",
    "Lyrics = [text for text in new_data['lyrics']]\n",
    "Lyrics[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69509ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and preprocess the lyrics\n",
    "def replace_char(lyrics):\n",
    "#     for i in range(len(lyrics)):\n",
    "#         lyrics[i] = re.sub(\"[\\(\\[].*?[\\)\\]]\",'',lyrics[i])\n",
    "#         lyrics[i] = re.sub(r'\\.+', \".\", lyrics[i])\n",
    "#         lyrics[i] = lyrics[i].replace(\"\\r\", \"\").replace(\"\\n\", \" \").replace(',', '').replace(\"\\'\",'').replace('/','').replace('-','').replace('...)','')\n",
    "#     return lyrics\n",
    "        \"\"\"\n",
    "        - remove any html tags (< /br> often found)\n",
    "        - Keep only ASCII + Latin chars, digits and whitespaces\n",
    "        - pad punctuation chars with whitespace\n",
    "        - convert all whitespaces (tabs etc.) to single wspace\n",
    "        \"\"\"\n",
    "        for i in range(len(lyrics)):\n",
    "            RE_PUNCTUATION = re.compile(\"([!?.,;-])\")\n",
    "            #RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "            RE_TAGS = re.compile(r\"[\\(\\[].*?[\\)\\]]\")\n",
    "            RE_ASCII = re.compile(r\"[^A-Za-z,.!?0-9 ]\", re.IGNORECASE)\n",
    "            RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "            lyrics[i] = re.sub(RE_TAGS, \" \", lyrics[i])\n",
    "            lyrics[i] = re.sub(RE_ASCII, \" \", lyrics[i])\n",
    "            lyrics[i] = re.sub(RE_PUNCTUATION, r\" \", lyrics[i])\n",
    "            lyrics[i] = re.sub(RE_WSPACE, \" \", lyrics[i])\n",
    "            lyrics[i] = lyrics[i].lower()\n",
    "        return lyrics\n",
    "\n",
    "    \n",
    "Lyrics_new = replace_char(Lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb245ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' i was almost about to lose my faith was still dreaming but feared it was too late but then you came along to my surprise and stole my heart before my very eyes you took me right out of the blue simply by showing that you love me too only by giving me your everything with a love so true you took me out of the blue i was wondering what love was all about i was trying but couldn t work it out but then you came along to my surprise and made my frozen mind come alive you took me right out of the blue simply by showing that you love me too you let me out of the darkness you brought me out in the sun i think you must be the only one for me cos you took me right out of the blue simply by showing that you love me too only by giving me your everything breathing air below my wings you took me right out of the night simply by filling my heart with light only by giving me your energy with a love so true you took me out of the blue <|endoftext|>',\n",
       " ' the sun is fading away that s the end of the day as the june light turns to moonlight i ll be on my way just one kiss and i ll go don t hide the tears that don t show as the june light turns to moonlight i ll be on my way to where the winds don t blow and golden rivers flow this way will i go they were right i was wrong true love didn t last long as the june light turns to moonlight i ll be on my way hey to where the winds don t blow and golden rivers flow this way will i go they were right i was wrong true love didn t last long as the june light turns to moonlight i ll be on my way hey i ll be on my way oh i ll be on my way oh i ll be on my way <|endoftext|>',\n",
       " ' oh please don t be so careless with your glances don t look at me that way and breathe a sigh please don t get too close and let me love you cause i just might be fool enough to try it s not that i don t think i m worthy of you but memories from the past i still recall please don t get too close and let me love you cause i just might be fool enough to fall it s not that i don t think i m worthy of you but memories from the past i still recall oh please don t get too close and let me love you cause i just might be fool enough to fall <|endoftext|>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add eos tokens to the end of the text\n",
    "Lyrics_new = [i + tokenizer.eos_token for i in Lyrics]\n",
    "Lyrics_new[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d27fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train & test data\n",
    "train_data, test_data = train_test_split(Lyrics_new, test_size = .3, random_state=42)\n",
    "\n",
    "train_data, val_data = train_test_split(train_data, test_size = .1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb77f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split predictor and labels\n",
    "def shift_right(data):\n",
    "    words = []\n",
    "    predictor_word =[]\n",
    "    labels_word = []\n",
    "    for i in range(len(data)):\n",
    "        words.append(list(filter(lambda x: x !='', re.split(r' ', data[i]))))\n",
    "        predictor_word.append(words[i][:-1])\n",
    "        labels_word.append(words[i][1:])\n",
    "        \n",
    "        \n",
    "    \n",
    "    predictor_list =[]\n",
    "    labels_list = []\n",
    "    for list_word in predictor_word:\n",
    "        predictor_list.append(' '.join(list_word))\n",
    "    for list_word in labels_word:\n",
    "        labels_list.append(' '.join(list_word))\n",
    "\n",
    "    return predictor_list, labels_list\n",
    "\n",
    "\n",
    "\n",
    "predictor_train, labels_train= shift_right(train_data)\n",
    "\n",
    "predictor_val, labels_val =  shift_right(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aabdf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the inputs for training and validating datset\n",
    "\n",
    "max_len = 180\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token \n",
    "\n",
    "predictor_train_token = tokenizer(predictor_train, return_tensors= 'tf',truncation = True, max_length = max_len, padding='max_length')\n",
    "# labels_train = tokenizer(labels_train, return_tensors= 'tf',truncation = True, max_length = max_len, padding='max_length')\n",
    "# labels_train_token = tokenizer(labels_train,truncation = True, max_length = max_len, padding='max_length')\n",
    "\n",
    "predictor_val_token = tokenizer(predictor_val,return_tensors= 'tf',truncation = True, max_length = max_len, padding='max_length')\n",
    "#labels_val = tokenizer(labels_val, return_tensors= 'tf',truncation = True, max_length = max_len, padding='max_length')\n",
    "\n",
    "labels_train_token = tokenizer(labels_train,truncation = True, max_length = max_len, padding='max_length')\n",
    "labels_val_token = tokenizer(labels_val, truncation = True, max_length = max_len, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec20560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set label's padding token labels to -100 which is ignored in loss computation\n",
    "def ignore_label_pad_token(labels_input_ids):\n",
    "    for idx, i in enumerate(labels_input_ids):\n",
    "        for t in range(len(i)):\n",
    "            if i[t]==tokenizer.eos_token_id:\n",
    "                i[t] = -100\n",
    "            else:\n",
    "                i[t] = i[t]\n",
    "                \n",
    "    return labels_input_ids\n",
    "\n",
    "labels_train_new = ignore_label_pad_token(labels_train_token.input_ids)\n",
    "labels_val_new = ignore_label_pad_token(labels_val_token.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01e9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert arrays to tensors\n",
    "labels_train_input_ids = tf.convert_to_tensor(labels_train_new, dtype=tf.int32)\n",
    "labels_val_input_ids = tf.convert_to_tensor(labels_val_new, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f912833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels which are array to tensors;\n",
    "#create tensorflow dataset that include all the inputs and outputs for model.fit, \n",
    "#shuffle, batch and prefech the dataset\n",
    "\n",
    "train_dataset = Dataset.from_tensor_slices(({'input_ids': predictor_train_token['input_ids'], 'attention_mask':predictor_train_token['attention_mask']}, labels_train_input_ids))\n",
    "train_dataset = train_dataset.shuffle(buffer_size =len(predictor_train_token),reshuffle_each_iteration=True)\n",
    "train_dataset = train_dataset.batch(8)\n",
    "train_dataset = train_dataset.prefetch(5)\n",
    "\n",
    "val_dataset = Dataset.from_tensor_slices(({'input_ids':predictor_val_token['input_ids'],'attention_mask':predictor_val_token['attention_mask']}, labels_val_input_ids))\n",
    "val_dataset = val_dataset.shuffle(buffer_size =len(predictor_val_token),reshuffle_each_iteration=True)\n",
    "val_dataset = val_dataset.batch(8)\n",
    "val_dataset = val_dataset.prefetch(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b828cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set customized learning rate, compile model\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "lr_schedule = optimizers.schedules.PolynomialDecay(\n",
    "initial_learning_rate=1e-5,\n",
    "decay_steps=10000,\n",
    "end_learning_rate=0, \n",
    "power=1.0)\n",
    "# lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "# initial_learning_rate=1e-6,\n",
    "# decay_steps=1000,\n",
    "# decay_rate=0.7,\n",
    "# staircase=True)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    loss = model.compute_loss,\n",
    "    metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint \n",
    "folder = '/content/lyrics_gpt'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "#filepath = '/Users/mycelebs_129/model6-{epoch:02d}-{val_sparse_categorical_accuracy:.2f}.hdf5'\n",
    "filepath = os.path.join(folder,  'lyrics_gen_BOS')\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor='val_loss', mode = 'min', save_freq='epoch',save_best_only=True, save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model and save best model \n",
    "model.fit(train_dataset,\n",
    "            validation_data = val_dataset,\n",
    "            epochs =1,\n",
    "            callbacks = [checkpoint_callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a540bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[12254,   502,   284,   262,  8824]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pretrained model weights\n",
    "model.load_weights(\"./lyrics_gen_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a34b1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[5460,  510,  287,  262, 6766]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first sentence of your lyrics\n",
    "first_sen = \"look up in the sky\"\n",
    "first_sen_input = tokenizer(first_sen, return_tensors = 'tf').input_ids\n",
    "first_sen_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "610f52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    }
   ],
   "source": [
    "#Generate lyrics \n",
    "#can play with the parameters to generate most ideal results\n",
    "set_seed(42)\n",
    "result = model.generate(first_sen_input, \n",
    "                        do_sample=True,\n",
    "                        #length_penalty =1.5,\n",
    "                        repetition_penalty=1.4,\n",
    "                        max_length=200,\n",
    "                        top_p=0.90, \n",
    "                        #top_k=50,\n",
    "                        #early_stopping = False,\n",
    "                        temperature =0.8,\n",
    "                        #num_beams = 20,\n",
    "                        #num_return_sequences =5\n",
    "                        #truncate=\"<|endoftext|>\",\n",
    "                        #result_as_list = True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98b9f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyrics_gen = [tokenizer.decode(i, skip_special_tokens = True) for i in result]\n",
    "lyrics_gen = tokenizer.decode(result[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d528f616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look up in the sky and see what we can do We re here to give you a ride Let us take that dream away from your mind Take it all back out of our heads Oh no You ve got me down by my side oh yeah What happened s wrong I m taking this trip And if ya want some more than just another meal then let yo ll be alright Come on baby cause they say come tryin for once They don t know how far apart There are so many different ways there is nothing left To get close enough Thats why when he finally cries his tears fall short but not long Before sunrise He gets better When those little things begin falling But only until one day will wake him Up again with every step Back home alone Is everything bad Baby It seems like life ain still going well So now stop crying cry Just start feeling good Now love won never break Cause nobody ever knows who died Ain d been waiting Don T worry darling My girl has found something sweet If she wants anything else Then please show'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff29c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
